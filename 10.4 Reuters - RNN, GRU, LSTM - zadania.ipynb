{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec31ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Wykonaj to robiliśmy do tej pory na zbiorze \"Reuters newswire\". sprawdź jak go zaladować z Tensorflow. Nie jest\n",
    "#wyamgane pobieranie pliku. Jak teraz zachowują się poszczególne modele?\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Embedding, Flatten\n",
    "n_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.reuters.load_data(num_words=n_words)\n",
    "\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b71c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 100\n",
    "\n",
    "X_train_pad = pad_sequences(X_train, maxlen=max_words, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea1d724",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unique'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527b04f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           80000     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                102464    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 182,529\n",
      "Trainable params: 182,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "281/281 [==============================] - 7s 12ms/step - loss: -7704.2041 - accuracy: 0.0479 - val_loss: -33358.1953 - val_accuracy: 0.0467\n",
      "Epoch 2/1000\n",
      "281/281 [==============================] - 3s 10ms/step - loss: -132319.2500 - accuracy: 0.0481 - val_loss: -290277.4062 - val_accuracy: 0.0467\n",
      "Epoch 3/1000\n",
      "281/281 [==============================] - 4s 14ms/step - loss: -588784.0000 - accuracy: 0.0481 - val_loss: -981355.5000 - val_accuracy: 0.0467\n",
      "Epoch 4/1000\n",
      "281/281 [==============================] - 3s 11ms/step - loss: -1546168.8750 - accuracy: 0.0481 - val_loss: -2236896.5000 - val_accuracy: 0.0467\n",
      "Epoch 5/1000\n",
      "281/281 [==============================] - 4s 14ms/step - loss: -3134777.7500 - accuracy: 0.0481 - val_loss: -4185001.0000 - val_accuracy: 0.0467\n",
      "Epoch 6/1000\n",
      "281/281 [==============================] - 3s 11ms/step - loss: -5454428.0000 - accuracy: 0.0481 - val_loss: -6899895.5000 - val_accuracy: 0.0467\n",
      "Epoch 7/1000\n",
      "281/281 [==============================] - 2s 9ms/step - loss: -8570981.0000 - accuracy: 0.0481 - val_loss: -10451005.0000 - val_accuracy: 0.0467\n",
      "Epoch 8/1000\n",
      "281/281 [==============================] - 3s 12ms/step - loss: -12537793.0000 - accuracy: 0.0481 - val_loss: -14869947.0000 - val_accuracy: 0.0467\n",
      "Epoch 9/1000\n",
      "281/281 [==============================] - 3s 11ms/step - loss: -17404654.0000 - accuracy: 0.0481 - val_loss: -20225748.0000 - val_accuracy: 0.0467\n",
      "Epoch 10/1000\n",
      "281/281 [==============================] - 2s 9ms/step - loss: -23225182.0000 - accuracy: 0.0481 - val_loss: -26536732.0000 - val_accuracy: 0.0467\n",
      "Epoch 11/1000\n",
      "281/281 [==============================] - 3s 11ms/step - loss: -30025002.0000 - accuracy: 0.0481 - val_loss: -33866284.0000 - val_accuracy: 0.0467\n",
      "Epoch 12/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -37807184.0000 - accuracy: 0.0481 - val_loss: -42198560.0000 - val_accuracy: 0.0467\n",
      "Epoch 13/1000\n",
      "281/281 [==============================] - 2s 9ms/step - loss: -46638836.0000 - accuracy: 0.0481 - val_loss: -51586576.0000 - val_accuracy: 0.0467\n",
      "Epoch 14/1000\n",
      "281/281 [==============================] - 3s 10ms/step - loss: -56534148.0000 - accuracy: 0.0481 - val_loss: -62070528.0000 - val_accuracy: 0.0467\n",
      "Epoch 15/1000\n",
      "281/281 [==============================] - 3s 9ms/step - loss: -67494184.0000 - accuracy: 0.0481 - val_loss: -73583880.0000 - val_accuracy: 0.0467\n",
      "Epoch 16/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -79572200.0000 - accuracy: 0.0481 - val_loss: -86302400.0000 - val_accuracy: 0.0467\n",
      "Epoch 17/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -92801216.0000 - accuracy: 0.0481 - val_loss: -100150200.0000 - val_accuracy: 0.0467\n",
      "Epoch 18/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -107207048.0000 - accuracy: 0.0481 - val_loss: -115195616.0000 - val_accuracy: 0.0467\n",
      "Epoch 19/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -122825160.0000 - accuracy: 0.0481 - val_loss: -131499240.0000 - val_accuracy: 0.0467\n",
      "Epoch 20/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -139723712.0000 - accuracy: 0.0481 - val_loss: -149067936.0000 - val_accuracy: 0.0467\n",
      "Epoch 21/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -157866160.0000 - accuracy: 0.0481 - val_loss: -167917968.0000 - val_accuracy: 0.0467\n",
      "Epoch 22/1000\n",
      "281/281 [==============================] - 3s 9ms/step - loss: -177268944.0000 - accuracy: 0.0481 - val_loss: -188046912.0000 - val_accuracy: 0.0467\n",
      "Epoch 23/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -198014704.0000 - accuracy: 0.0481 - val_loss: -209540096.0000 - val_accuracy: 0.0467\n",
      "Epoch 24/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -220127280.0000 - accuracy: 0.0481 - val_loss: -232378480.0000 - val_accuracy: 0.0467\n",
      "Epoch 25/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -243635472.0000 - accuracy: 0.0481 - val_loss: -256600112.0000 - val_accuracy: 0.0467\n",
      "Epoch 26/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -268559776.0000 - accuracy: 0.0481 - val_loss: -282392512.0000 - val_accuracy: 0.0467\n",
      "Epoch 27/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -294943744.0000 - accuracy: 0.0481 - val_loss: -309564832.0000 - val_accuracy: 0.0467\n",
      "Epoch 28/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -322842112.0000 - accuracy: 0.0481 - val_loss: -338363520.0000 - val_accuracy: 0.0467\n",
      "Epoch 29/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -352263648.0000 - accuracy: 0.0481 - val_loss: -368659680.0000 - val_accuracy: 0.0467\n",
      "Epoch 30/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -383206816.0000 - accuracy: 0.0481 - val_loss: -400433056.0000 - val_accuracy: 0.0467\n",
      "Epoch 31/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -415730880.0000 - accuracy: 0.0481 - val_loss: -433883328.0000 - val_accuracy: 0.0467\n",
      "Epoch 32/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -449897024.0000 - accuracy: 0.0481 - val_loss: -468957216.0000 - val_accuracy: 0.0467\n",
      "Epoch 33/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -485697120.0000 - accuracy: 0.0481 - val_loss: -505650784.0000 - val_accuracy: 0.0467\n",
      "Epoch 34/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -523158624.0000 - accuracy: 0.0481 - val_loss: -544095552.0000 - val_accuracy: 0.0467\n",
      "Epoch 35/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -562349888.0000 - accuracy: 0.0481 - val_loss: -584267136.0000 - val_accuracy: 0.0467\n",
      "Epoch 36/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -603319488.0000 - accuracy: 0.0481 - val_loss: -626227840.0000 - val_accuracy: 0.0467\n",
      "Epoch 37/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -646041088.0000 - accuracy: 0.0481 - val_loss: -670076992.0000 - val_accuracy: 0.0467\n",
      "Epoch 38/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -690676096.0000 - accuracy: 0.0481 - val_loss: -715707392.0000 - val_accuracy: 0.0467\n",
      "Epoch 39/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -737192896.0000 - accuracy: 0.0481 - val_loss: -763365120.0000 - val_accuracy: 0.0467\n",
      "Epoch 40/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -785540096.0000 - accuracy: 0.0481 - val_loss: -812787200.0000 - val_accuracy: 0.0467\n",
      "Epoch 41/1000\n",
      "281/281 [==============================] - 3s 9ms/step - loss: -835737280.0000 - accuracy: 0.0481 - val_loss: -864028864.0000 - val_accuracy: 0.0467\n",
      "Epoch 42/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -887911744.0000 - accuracy: 0.0481 - val_loss: -917419968.0000 - val_accuracy: 0.0467\n",
      "Epoch 43/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -942056832.0000 - accuracy: 0.0481 - val_loss: -972776000.0000 - val_accuracy: 0.0467\n",
      "Epoch 44/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -998167040.0000 - accuracy: 0.0481 - val_loss: -1030035648.0000 - val_accuracy: 0.0467\n",
      "Epoch 45/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -1056372160.0000 - accuracy: 0.0481 - val_loss: -1089343616.0000 - val_accuracy: 0.0467\n",
      "Epoch 46/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -1116625664.0000 - accuracy: 0.0481 - val_loss: -1150917504.0000 - val_accuracy: 0.0467\n",
      "Epoch 47/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -1179035392.0000 - accuracy: 0.0481 - val_loss: -1214532096.0000 - val_accuracy: 0.0467\n",
      "Epoch 48/1000\n",
      "281/281 [==============================] - 2s 6ms/step - loss: -1243629696.0000 - accuracy: 0.0481 - val_loss: -1280524160.0000 - val_accuracy: 0.0467\n",
      "Epoch 49/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -1310223488.0000 - accuracy: 0.0481 - val_loss: -1348293632.0000 - val_accuracy: 0.0467\n",
      "Epoch 50/1000\n",
      "281/281 [==============================] - 2s 7ms/step - loss: -1379026688.0000 - accuracy: 0.0481 - val_loss: -1418352000.0000 - val_accuracy: 0.0467\n",
      "Epoch 51/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -1450034048.0000 - accuracy: 0.0481 - val_loss: -1490699776.0000 - val_accuracy: 0.0467\n",
      "Epoch 52/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -1523237248.0000 - accuracy: 0.0481 - val_loss: -1565264256.0000 - val_accuracy: 0.0467\n",
      "Epoch 53/1000\n",
      "281/281 [==============================] - 3s 12ms/step - loss: -1598888448.0000 - accuracy: 0.0481 - val_loss: -1642519552.0000 - val_accuracy: 0.0467\n",
      "Epoch 54/1000\n",
      "281/281 [==============================] - 3s 12ms/step - loss: -1676750720.0000 - accuracy: 0.0481 - val_loss: -1721542784.0000 - val_accuracy: 0.0467\n",
      "Epoch 55/1000\n",
      "281/281 [==============================] - 3s 9ms/step - loss: -1756859264.0000 - accuracy: 0.0481 - val_loss: -1803121536.0000 - val_accuracy: 0.0467\n",
      "Epoch 56/1000\n",
      "281/281 [==============================] - 3s 10ms/step - loss: -1839402112.0000 - accuracy: 0.0481 - val_loss: -1886979072.0000 - val_accuracy: 0.0467\n",
      "Epoch 57/1000\n",
      "281/281 [==============================] - 4s 15ms/step - loss: -1924283904.0000 - accuracy: 0.0481 - val_loss: -1973411840.0000 - val_accuracy: 0.0467\n",
      "Epoch 58/1000\n",
      "281/281 [==============================] - 2s 8ms/step - loss: -2011561472.0000 - accuracy: 0.0481 - val_loss: -2062100608.0000 - val_accuracy: 0.0467\n",
      "Epoch 59/1000\n",
      "247/281 [=========================>....] - ETA: 0s - loss: -2105306752.0000 - accuracy: 0.0493"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model2.add(SimpleRNN(32))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.summary()\n",
    "model2.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model3.add(GRU(32))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.summary()\n",
    "model3.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history3 = model3.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model4.add(LSTM(32))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(64, activation='relu'))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "model4.summary()\n",
    "model4.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history4 = model4.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47137ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
