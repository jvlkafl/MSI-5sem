{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d385895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Na podstawie poprzedniego pliku stwórz 4 modele:\n",
    "#1. z warstwą embedding\n",
    "#2. z warstwą embedding i warstwą SimpleRNN (między embedding a dense), wyposażoną w 32 neurony\n",
    "#3. z warstwą embedding i warstwą GRU (między embedding a dense), wyposażoną w 32 neurony\n",
    "#4. z warstwą embedding i warstwą LSTM (między embedding a dense), wyposażoną w 32 neurony\n",
    "#Dla każdego modelu stwórz wykresy. Która sieć poradziła sobie najlepiej?\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Embedding, Flatten\n",
    "n_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=n_words)\n",
    "\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987870d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 100\n",
    "\n",
    "X_train_pad = pad_sequences(X_train, maxlen=max_words, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09c9c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           80000     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                102464    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 182,529\n",
      "Trainable params: 182,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "782/782 [==============================] - 43s 29ms/step - loss: 0.4411 - accuracy: 0.7806 - val_loss: 0.3409 - val_accuracy: 0.8496\n",
      "Epoch 2/1000\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 0.2237 - accuracy: 0.9129 - val_loss: 0.4037 - val_accuracy: 0.8307\n",
      "Epoch 3/1000\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.0815 - accuracy: 0.9752 - val_loss: 0.5694 - val_accuracy: 0.8162\n",
      "Epoch 4/1000\n",
      "782/782 [==============================] - 23s 30ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.7213 - val_accuracy: 0.8190\n",
      "Epoch 5/1000\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.8369 - val_accuracy: 0.8217\n",
      "Epoch 6/1000\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.8852 - val_accuracy: 0.8233\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60fb67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 16)           80000     \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                1568      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,745\n",
      "Trainable params: 83,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "782/782 [==============================] - 69s 70ms/step - loss: 0.5579 - accuracy: 0.6954 - val_loss: 0.3974 - val_accuracy: 0.8264\n",
      "Epoch 2/1000\n",
      "782/782 [==============================] - 45s 58ms/step - loss: 0.3614 - accuracy: 0.8475 - val_loss: 0.3797 - val_accuracy: 0.8369\n",
      "Epoch 3/1000\n",
      "782/782 [==============================] - 48s 62ms/step - loss: 0.2892 - accuracy: 0.8852 - val_loss: 0.4277 - val_accuracy: 0.8298\n",
      "Epoch 4/1000\n",
      "782/782 [==============================] - 42s 54ms/step - loss: 0.2273 - accuracy: 0.9116 - val_loss: 0.4592 - val_accuracy: 0.8265\n",
      "Epoch 5/1000\n",
      "782/782 [==============================] - 44s 57ms/step - loss: 0.1624 - accuracy: 0.9403 - val_loss: 0.5430 - val_accuracy: 0.8128\n",
      "Epoch 6/1000\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.1173 - accuracy: 0.9593 - val_loss: 0.6566 - val_accuracy: 0.7612\n",
      "Epoch 7/1000\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 0.0948 - accuracy: 0.9672 - val_loss: 0.7280 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model2.add(SimpleRNN(32))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.summary()\n",
    "model2.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history2 = model2.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbafb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 16)           80000     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 32)                4800      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,977\n",
      "Trainable params: 86,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "782/782 [==============================] - 129s 127ms/step - loss: 0.4748 - accuracy: 0.7574 - val_loss: 0.3717 - val_accuracy: 0.8331\n",
      "Epoch 2/1000\n",
      "782/782 [==============================] - 97s 124ms/step - loss: 0.3050 - accuracy: 0.8704 - val_loss: 0.3455 - val_accuracy: 0.8464\n",
      "Epoch 3/1000\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.2679 - accuracy: 0.8896 - val_loss: 0.3404 - val_accuracy: 0.8515\n",
      "Epoch 4/1000\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.2364 - accuracy: 0.9070 - val_loss: 0.3513 - val_accuracy: 0.8499\n",
      "Epoch 5/1000\n",
      "782/782 [==============================] - 93s 119ms/step - loss: 0.2027 - accuracy: 0.9200 - val_loss: 0.3935 - val_accuracy: 0.8464\n",
      "Epoch 6/1000\n",
      "782/782 [==============================] - 92s 118ms/step - loss: 0.1726 - accuracy: 0.9332 - val_loss: 0.4376 - val_accuracy: 0.8457\n",
      "Epoch 7/1000\n",
      "782/782 [==============================] - 90s 115ms/step - loss: 0.1434 - accuracy: 0.9466 - val_loss: 0.4743 - val_accuracy: 0.8428\n",
      "Epoch 8/1000\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.1222 - accuracy: 0.9550 - val_loss: 0.4829 - val_accuracy: 0.8399\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model3.add(GRU(32))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.summary()\n",
    "model3.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history3 = model3.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851e3f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 100, 16)           80000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                6272      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,449\n",
      "Trainable params: 88,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "782/782 [==============================] - 99s 105ms/step - loss: 0.4343 - accuracy: 0.7888 - val_loss: 0.3633 - val_accuracy: 0.8400\n",
      "Epoch 2/1000\n",
      "782/782 [==============================] - 82s 105ms/step - loss: 0.3009 - accuracy: 0.8748 - val_loss: 0.3590 - val_accuracy: 0.8496\n",
      "Epoch 3/1000\n",
      "782/782 [==============================] - 91s 117ms/step - loss: 0.2593 - accuracy: 0.8942 - val_loss: 0.3425 - val_accuracy: 0.8514\n",
      "Epoch 4/1000\n",
      "782/782 [==============================] - 86s 111ms/step - loss: 0.2215 - accuracy: 0.9129 - val_loss: 0.3859 - val_accuracy: 0.8432\n",
      "Epoch 5/1000\n",
      "782/782 [==============================] - 85s 109ms/step - loss: 0.1925 - accuracy: 0.9260 - val_loss: 0.3994 - val_accuracy: 0.8384\n",
      "Epoch 6/1000\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 0.1659 - accuracy: 0.9376 - val_loss: 0.5056 - val_accuracy: 0.8330\n",
      "Epoch 7/1000\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.1482 - accuracy: 0.9454 - val_loss: 0.4871 - val_accuracy: 0.8281\n",
      "Epoch 8/1000\n",
      "782/782 [==============================] - 90s 115ms/step - loss: 0.1324 - accuracy: 0.9514 - val_loss: 0.5811 - val_accuracy: 0.8238\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model4.add(LSTM(32))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(64, activation='relu'))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "model4.summary()\n",
    "model4.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history4 = model4.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ea7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
